{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP week 4",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/z1qsx/myANLP/blob/master/NLP_week_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "doYDYv-7eCT2",
        "colab_type": "code",
        "outputId": "d9c0d7e0-9ddf-42cb-de6c-ea384a28379f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZR9rfGQ_w6xw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.File reading "
      ]
    },
    {
      "metadata": {
        "id": "348DWTRHfFRb",
        "colab_type": "code",
        "outputId": "053707b2-a636-4813-d208-f4de9113f0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import os,random,math\n",
        "from nltk import word_tokenize as tokenize\n",
        "import operator\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "TRAINING_DIR=\"/content/gdrive/My Drive/csv/nlp/sentence-completion/Holmes_Training_Data\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gyer0aA8xC_f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.Spliting training files and heldout files"
      ]
    },
    {
      "metadata": {
        "id": "C7zVPsgLgXHV",
        "colab_type": "code",
        "outputId": "ed8814b9-b08d-4309-d7e4-a7a7cb5d0bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "def get_training_testing(training_dir=TRAINING_DIR,split=0.5):\n",
        "    filenames=os.listdir(training_dir)\n",
        "    n=len(filenames) \n",
        "    print(\"There are {} files in the training directory: {}\".format(n,training_dir))\n",
        "    #random.seed(53) #if you want the same random split every time \n",
        "    random.shuffle(filenames) \n",
        "    index=int(n*split) \n",
        "    return(filenames[:index],filenames[index:])\n",
        "trainingfiles,heldoutfiles=get_training_testing()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 522 files in the training directory: /content/gdrive/My Drive/csv/nlp/sentence-completion/Holmes_Training_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0cirgvnxj7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Building the language model"
      ]
    },
    {
      "metadata": {
        "id": "WUare7oIglN3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class language_model(object):\n",
        "    \n",
        "    def __init__(self,trainingdir=TRAINING_DIR,files=[]):\n",
        "        self.training_dir=trainingdir\n",
        "        self.files=files\n",
        "        self.train()\n",
        "        \n",
        "    def train(self):    \n",
        "        self.unigram={}\n",
        "        self.bigram={}\n",
        "\n",
        "        self._processfiles()\n",
        "        self._make_unknowns()\n",
        "        self._discount()\n",
        "        self._convert_to_probs()\n",
        "        \n",
        "        \n",
        "    \n",
        "    def _processline(self,line):\n",
        "        tokens=[\"__START\"]+tokenize(line)+[\"__END\"]\n",
        "        previous=\"__END\"\n",
        "        \n",
        "        for token in tokens:\n",
        "            self.unigram[token]=self.unigram.get(token,0)+1\n",
        "            \n",
        "            current=self.bigram.get(previous,{})\n",
        "            \n",
        "            current[token]=current.get(token,0)+1\n",
        "\n",
        "            self.bigram[previous]=current\n",
        "            \n",
        "            previous=token\n",
        "            \n",
        "    \n",
        "    def _processfiles(self):\n",
        "        for afile in self.files:\n",
        "            print(\"Processing {}\".format(afile))\n",
        "            try:\n",
        "                with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "                    for line in instream:\n",
        "                        line=line.rstrip()\n",
        "                        if len(line)>0:\n",
        "                            self._processline(line)\n",
        "            except UnicodeDecodeError:\n",
        "                print(\"UnicodeDecodeError processing {}: ignoring rest of file\".format(afile))\n",
        "      \n",
        "            \n",
        "    def _convert_to_probs(self):\n",
        "        \n",
        "        self.unigram={k:v/sum(self.unigram.values()) for (k,v) in self.unigram.items()}\n",
        "        self.bigram={key:{k:v/sum(adict.values()) for (k,v) in adict.items()} for (key,adict) in self.bigram.items()}\n",
        "        \n",
        "    \n",
        "    \n",
        "    def _make_unknowns(self,known=2):\n",
        "      unknown=0\n",
        "      for (k,v) in list(self.unigram.items()):\n",
        "          if v<known:\n",
        "              del self.unigram[k]\n",
        "              self.unigram[\"__UNK\"]=self.unigram.get(\"__UNK\",0)+v\n",
        "      for (k,adict) in list(self.bigram.items()):\n",
        "          for (kk,v) in list(adict.items()):\n",
        "              isknown=self.unigram.get(kk,0)\n",
        "              if isknown==0:\n",
        "                  adict[\"__UNK\"]=adict.get(\"__UNK\",0)+v\n",
        "                  del adict[kk]\n",
        "          isknown=self.unigram.get(k,0)\n",
        "          if isknown==0:\n",
        "              del self.bigram[k]\n",
        "              current=self.bigram.get(\"__UNK\",{})\n",
        "              current.update(adict)\n",
        "              self.bigram[\"__UNK\"]=current\n",
        "\n",
        "          else:\n",
        "              self.bigram[k]=adict\n",
        "    \n",
        "    \n",
        "    def _discount(self,discount=0.75):\n",
        "        #discount each bigram count by a small fixed amount\n",
        "        self.bigram={k:{kk:value-discount for (kk,value) in adict.items()}for (k,adict) in self.bigram.items()}\n",
        "\n",
        "        #for each word, store the total amount of the discount so that the total is the same \n",
        "        #i.e., so we are reserving this as probability mass\n",
        "        for k in self.bigram.keys():\n",
        "            lamb=len(self.bigram[k])\n",
        "            self.bigram[k][\"__DISCOUNT\"]=lamb*discount\n",
        "\n",
        "        #work out kneser-ney unigram probabilities\n",
        "        #count the number of contexts each word has been seen in\n",
        "        self.kn={}\n",
        "        for (k,adict) in self.bigram.items():\n",
        "            for kk in adict.keys():\n",
        "                self.kn[kk]=self.kn.get(kk,0)+1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o5PkXGTE9Z4e",
        "colab_type": "code",
        "outputId": "ea9ea4eb-8b21-4867-a9fe-25b24f90d31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_FILES=1\n",
        "my_relsuts=language_model(files=trainingfiles[:MAX_FILES])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing HYDEA10.TXT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HJokTAcX28Fw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "XsdwoVytgpXe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class language_model_get_prob(language_model):\n",
        "  \n",
        "  def get_prob(self,token,context=\"\",methodparams={}):\n",
        "    \n",
        "    if methodparams.get(\"method\",\"unigram\")==\"unigram\":\n",
        "        return self.unigram.get(token,self.unigram.get(\"__UNK\",0))\n",
        "    else:\n",
        "        if methodparams.get(\"smoothing\",\"kneser-ney\")==\"kneser-ney\":\n",
        "            unidist=self.kn\n",
        "        else:\n",
        "            unidist=self.unigram\n",
        "            \n",
        "        bigram=self.bigram.get(context[-1],self.bigram.get(\"__UNK\",{}))\n",
        "        big_p=bigram.get(token,bigram.get(\"__UNK\",0))\n",
        "        lmbda=bigram[\"__DISCOUNT\"]\n",
        "        uni_p=unidist.get(token,unidist.get(\"__UNK\",0))\n",
        "        #print(big_p,lmbda,uni_p)\n",
        "        p=big_p+lmbda*uni_p            \n",
        "        return p\n",
        "\n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ULCGP1JBglK",
        "colab_type": "code",
        "outputId": "321256a3-bdaf-45b9-ec6a-93a5786698a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "prob=language_model_get_prob(files=trainingfiles[:MAX_FILES])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing HYDEA10.TXT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IH-36A9lBzlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Person(object):\n",
        "  def __init__(self,name,sex):\n",
        "    self.name = name\n",
        "    self.sex = sex\n",
        "\n",
        "  def print_title(self):\n",
        "    if self.sex == \"male\":\n",
        "      print(\"man\")\n",
        "    elif self.sex == \"female\":\n",
        "      print(\"woman\")\n",
        "            \n",
        "class Child(Person):\n",
        "  pass\n",
        "\n",
        "class Baby(Child):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Av4tDfMNFXyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s=Child"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWJfZtYz2wWM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Generating the sentence\n"
      ]
    },
    {
      "metadata": {
        "id": "MJW7dAPu1Nco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class language_model_sentence(language_model_get_prob):\n",
        "\n",
        "  def nextlikely(self,k=1,current=\"\",method=\"unigram\"):\n",
        "      #use probabilities according to method to generate a likely next sequence\n",
        "      #choose random token from k best\n",
        "      blacklist=[\"__START\",\"__UNK\",\"__DISCOUNT\"]\n",
        "\n",
        "      if method==\"unigram\":\n",
        "          dist=self.unigram\n",
        "      else:\n",
        "          dist=self.bigram.get(current,self.bigram.get(\"__UNK\",{}))\n",
        "\n",
        "      #sort the tokens by unigram probability\n",
        "      mostlikely=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "      \n",
        "      #filter out any undesirable tokens\n",
        "      filtered=[w for (w,p) in mostlikely if w not in blacklist]\n",
        "      #choose one randomly from the top k\n",
        "      res=random.choice(filtered[:k])\n",
        "      return res\n",
        "\n",
        "  def generate(self,k=1,end=\"__END\",limit=20,method=\"bigram\",methodparams={}):\n",
        "      if method==\"\":\n",
        "          method=methodparams.get(\"method\",\"bigram\")\n",
        "      current=\"__START\"\n",
        "      tokens=[]\n",
        "      while current!=end and len(tokens)<limit:\n",
        "          current=self.nextlikely(k=k,current=current,method=method)\n",
        "          tokens.append(current)\n",
        "      return \" \".join(tokens[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "scR9AyzfIwc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sorted method"
      ]
    },
    {
      "metadata": {
        "id": "F_nah26CIGPC",
        "colab_type": "code",
        "outputId": "ea2a248f-bc51-4cb1-afa2-9e76a3775883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "a = [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'C', 10)]\n",
        "\n",
        "sorted(a, key=operator.itemgetter(1),reverse=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dave', 'C', 10), ('jane', 'B', 12), ('john', 'A', 15)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "Qc2Ejh_-Dezj",
        "colab_type": "code",
        "outputId": "b5de5173-080f-455d-8d3a-aa2d908bc89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sents=language_model_sentence(files=trainingfiles[:MAX_FILES])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing HYDEA10.TXT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DO0WszbG6d6X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "5. "
      ]
    },
    {
      "metadata": {
        "id": "4Hoaj7Md2vTq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class language_model_perplexity(language_model_get_prob):\n",
        "  \n",
        "  def _convert_to_probs(self):\n",
        "        \n",
        "    self.unigram={k:v/sum(self.unigram.values()) for (k,v) in self.unigram.items()}\n",
        "    self.bigram={key:{k:v/sum(adict.values()) for (k,v) in adict.items()} for (key,adict) in self.bigram.items()}\n",
        "    self.kn={k:v/sum(self.kn.values()) for (k,v) in self.kn.items()}\n",
        "\n",
        "  def compute_prob_line(self,line,methodparams={}):\n",
        "    #this will add _start to the beginning of a line of text\n",
        "    #compute the probability of the line according to the desired model\n",
        "    #and returns probability together with number of tokens\n",
        "\n",
        "    tokens=[\"__START\"]+tokenize(line)+[\"__END\"]\n",
        "    acc=0\n",
        "    for i,token in enumerate(tokens[1:]):\n",
        "        acc+=math.log(self.get_prob(token,tokens[:i+1],methodparams))\n",
        "    return acc,len(tokens[1:])\n",
        "\n",
        "  def compute_probability(self,filenames=[],methodparams={}):\n",
        "      #computes the probability (and length) of a corpus contained in filenames\n",
        "      if filenames==[]:\n",
        "          filenames=self.files\n",
        "\n",
        "      total_p=0\n",
        "      total_N=0\n",
        "      for i,afile in enumerate(filenames):\n",
        "          print(\"Processing file {}:{}\".format(i,afile))\n",
        "          try:\n",
        "              with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "                  for line in instream:\n",
        "                      line=line.rstrip()\n",
        "                      if len(line)>0:\n",
        "                          p,N=self.compute_prob_line(line,methodparams=methodparams)\n",
        "                          total_p+=p\n",
        "                          total_N+=N\n",
        "          except UnicodeDecodeError:\n",
        "              print(\"UnicodeDecodeError processing file {}: ignoring rest of file\".format(afile))\n",
        "      return total_p,total_N\n",
        "\n",
        "  def compute_perplexity(self,filenames=[],methodparams={\"method\":\"bigram\",\"smoothing\":\"kneser-ney\"}):\n",
        "\n",
        "      #compute the probability and length of the corpus\n",
        "      #calculate perplexity\n",
        "      #lower perplexity means that the model better explains the data\n",
        "\n",
        "      p,N=self.compute_probability(filenames=filenames,methodparams=methodparams)\n",
        "      #print(p,N)\n",
        "      pp=math.exp(-p/N)\n",
        "      return pp  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DVe1QhhZZJy",
        "colab_type": "code",
        "outputId": "0895fa4c-a924-44ee-8b78-e1bb137a1626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "pre_unkonw=language_model_perplexity(files=trainingfiles[:MAX_FILES])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing HYDEA10.TXT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1oxnCuUeZ02e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bigram=pre_unkonw.bigram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2mJlUptmkpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fg7yP18Dm0PC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compute_perplexity"
      ]
    },
    {
      "metadata": {
        "id": "C83EyclQm_BC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "drRtcKH3m-YD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens=[\"__START\"]+tokenize(line)+[\"__END\"]\n",
        "pre=0\n",
        "for i,token in enumerate(tokens[1:]):\n",
        "    pre+=math.log(self.get_prob(token,tokens[:i+1],methodparams))\n",
        "return pre,len(tokens[1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsNfh2ywn8VZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p,N=self.compute_prob_line(line,methodparams=methodparams)\n",
        "total_p+=p\n",
        "total_N+=N"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWaWmOzPoAW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p,N=self.compute_probability(filenames=filenames,methodparams=methodparams)\n",
        "#print(p,N)\n",
        "pp=math.exp(-p/N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIyBlOaNoM2U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discount"
      ]
    },
    {
      "metadata": {
        "id": "lATaOW0doMYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " for k in self.bigram.keys():\n",
        "    lamb=len(self.bigram[k])\n",
        "    self.bigram[k][\"__DISCOUNT\"]=lamb*discount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7yDRrHBfoTys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "self.kn={k:v/sum(self.kn.values()) for (k,v) in self.kn.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}